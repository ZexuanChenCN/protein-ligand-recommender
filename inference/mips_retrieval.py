"""
Protein-Ligandæ£€ç´¢ç³»ç»Ÿ - æœ€ç»ˆå®Œæ•´ç‰ˆ
æ ¸å¿ƒä¿®å¤ï¼š
1. å½»åº•è§£å†³äº²å’ŒåŠ›åŒ¹é…å¤±è´¥é—®é¢˜ï¼ˆç²¾ç¡®+æ¨¡ç³ŠåŒ¹é…ï¼‰
2. ä¼˜åŒ–æ¸©åº¦ç³»æ•°ï¼Œæå‡ç›¸ä¼¼åº¦åŒºåˆ†åº¦
3. æ–°å¢æµ‹è¯•æ ·æœ¬äº²å’ŒåŠ›éªŒè¯é€»è¾‘
4. å®Œå–„çš„æ—¥å¿—å’Œé”™è¯¯å¤„ç†
"""
import torch
import numpy as np
import warnings
from tqdm import tqdm
import faiss
warnings.filterwarnings("ignore")

# ==================== æ¨¡å‹å®šä¹‰ï¼ˆç‹¬ç«‹å¯è¿è¡Œï¼‰ ====================
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoModel, AutoTokenizer

class SimpleProteinEncoder(nn.Module):
    def __init__(self, vocab_size=21, embed_dim=128, hidden_dim=256, proj_dim=256, dropout=0.2):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=True, batch_first=True)
        self.proj = nn.Sequential(
            nn.Linear(hidden_dim * 2, proj_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(proj_dim, proj_dim)
        )
        self.dropout = nn.Dropout(dropout)

    def forward(self, seqs):
        aa_vocab = {'A':0, 'C':1, 'D':2, 'E':3, 'F':4, 'G':5, 'H':6,
                    'I':7, 'K':8, 'L':9, 'M':10, 'N':11, 'P':12, 'Q':13,
                    'R':14, 'S':15, 'T':16, 'V':17, 'W':18, 'Y':19, 'X':20}

        max_len = max(len(seq) for seq in seqs)
        batch_emb = []
        for seq in seqs:
            seq_ids = [aa_vocab.get(c, 20) for c in seq[:max_len]]
            seq_ids += [20] * (max_len - len(seq_ids))
            batch_emb.append(seq_ids)

        x = torch.tensor(batch_emb).to(self.embedding.weight.device)
        x = self.embedding(x)
        x = self.dropout(x)

        lstm_out, _ = self.lstm(x)
        lstm_pool = lstm_out.mean(dim=1)
        proj_out = self.proj(lstm_pool)

        return F.normalize(proj_out, p=2, dim=-1)

class ChemBERTaEncoder(nn.Module):
    def __init__(self, model_name="DeepChem/ChemBERTa-77M-MLM", proj_dim=256, dropout=0.2):
        super().__init__()
        self.bert = AutoModel.from_pretrained(model_name)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.proj = nn.Sequential(
            nn.Linear(self.bert.config.hidden_size, proj_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(proj_dim, proj_dim)
        )
        self.dropout = nn.Dropout(dropout)

    def forward(self, smiles_list):
        inputs = self.tokenizer(
            smiles_list,
            padding=True,
            truncation=True,
            max_length=128,
            return_tensors="pt"
        ).to(self.bert.device)

        bert_out = self.bert(**inputs)
        cls_out = bert_out.last_hidden_state[:, 0, :]
        cls_out = self.dropout(cls_out)

        proj_out = self.proj(cls_out)

        return F.normalize(proj_out, p=2, dim=-1)

class CLIPStyleDualTower(nn.Module):
    def __init__(self, protein_embed_dim=128, proj_dim=256, init_temperature=0.2,
                 dropout=0.2, **kwargs):
        super().__init__()
        self.protein_encoder = SimpleProteinEncoder(
            embed_dim=protein_embed_dim,
            proj_dim=proj_dim,
            dropout=dropout
        )

        self.ligand_encoder = ChemBERTaEncoder(
            proj_dim=proj_dim,
            dropout=dropout
        )

        self.temperature = torch.nn.Parameter(torch.tensor(init_temperature))
        self.proj_dim = proj_dim

    def encode_protein(self, protein_seqs):
        return self.protein_encoder(protein_seqs)

    def encode_ligand(self, ligand_smiles):
        return self.ligand_encoder(ligand_smiles)

    def forward(self, protein_seqs, ligand_smiles, neg_ligand_smiles=None):
        protein_embs = self.encode_protein(protein_seqs)
        ligand_embs = self.encode_ligand(ligand_smiles)

        sim = torch.matmul(protein_embs, ligand_embs.t()) / self.temperature

        if neg_ligand_smiles is not None:
            neg_ligand_embs = self.encode_ligand(neg_ligand_smiles)
            neg_sim = torch.matmul(protein_embs, neg_ligand_embs.t()) / self.temperature
            return sim, neg_sim

        return sim

    @classmethod
    def load_from_checkpoint(cls, checkpoint_path, **kwargs):
        checkpoint = torch.load(checkpoint_path, map_location="cpu")
        model = cls(**kwargs)
        model.load_state_dict(checkpoint["state_dict"], strict=False)
        return model

# ==================== æ£€ç´¢å™¨æ ¸å¿ƒç±»ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆï¼‰ ====================
class ProteinLigandRetriever:
    def __init__(self, checkpoint_path, device="cuda:0", temperature_scale=0.5):
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        print(f"æ£€ç´¢å™¨åˆå§‹åŒ–è®¾å¤‡ï¼š{self.device}")

        # åŠ è½½æ¨¡å‹
        print(f"åŠ è½½æ¨¡å‹ checkpointï¼š{checkpoint_path}")
        self.model = CLIPStyleDualTower.load_from_checkpoint(
            checkpoint_path,
            protein_embed_dim=256,
            proj_dim=256,
            init_temperature=0.2,
            dropout=0.2
        ).to(self.device)

        # è¯„ä¼°æ¨¡å¼
        self.model.eval()

        # å›ºå®šæ¸©åº¦ç³»æ•°
        self.model.temperature.data = torch.tensor(temperature_scale).to(self.device)
        print(f"âœ… æ‰‹åŠ¨è°ƒæ•´æ¨¡å‹æ¸©åº¦ç³»æ•°ä¸ºï¼š{self.model.temperature.item():.8f}")

        # åˆå§‹åŒ–ç´¢å¼•å’Œæ•°æ®åº“
        self.protein_index = None
        self.ligand_index = None
        self.protein_id2seq = {}
        self.ligand_id2smiles = {}
        self.affinity_db = {}
        self.raw_dataset_samples = []

    def preprocess_protein(self, seq):
        """è›‹ç™½åºåˆ—é¢„å¤„ç†"""
        aa_vocab = {'A':0, 'C':1, 'D':2, 'E':3, 'F':4, 'G':5, 'H':6,
                    'I':7, 'K':8, 'L':9, 'M':10, 'N':11, 'P':12, 'Q':13,
                    'R':14, 'S':15, 'T':16, 'V':17, 'W':18, 'Y':19, 'X':20}
        max_len = 1024

        seq = seq.upper()
        seq = ''.join([c for c in seq if c in aa_vocab.keys()])
        seq = seq[:max_len]
        return seq

    def preprocess_ligand(self, smiles):
        """SMILESé¢„å¤„ç†"""
        if not smiles or len(smiles) < 1:
            return "C"
        return smiles.replace(' ', '').lower()

    def encode_protein_batch(self, protein_seqs):
        """æ‰¹é‡ç¼–ç è›‹ç™½"""
        processed_seqs = [self.preprocess_protein(seq) for seq in protein_seqs]
        with torch.no_grad():
            protein_emb = self.model.encode_protein(processed_seqs)
        return protein_emb.cpu().numpy()

    def encode_ligand_batch(self, ligand_smiles):
        """æ‰¹é‡ç¼–ç å°åˆ†å­"""
        processed_smiles = [self.preprocess_ligand(smi) for smi in ligand_smiles]
        with torch.no_grad():
            ligand_emb = self.model.encode_ligand(processed_smiles)
        return ligand_emb.cpu().numpy()

    def build_indexes_from_dataset(self, dataset, max_proteins=2000, max_ligands=8000):
        """æ„å»ºç´¢å¼•å’Œäº²å’ŒåŠ›æ•°æ®åº“"""
        print("åŠ è½½æ•°æ®é›†ï¼šBALM/BALM-benchmark - BindingDB_filtered")
        dataset = dataset["train"]

        # è¿‡æ»¤æ— æ•ˆæ ·æœ¬
        def filter_invalid(sample):
            return (sample["Target"] and len(sample["Target"]) > 10 and
                    sample["Drug"] and len(sample["Drug"]) > 1 and
                    sample["Y"] is not None and sample["Y"] >= 0)

        dataset = dataset.filter(filter_invalid)
        self.raw_dataset_samples = [s for s in dataset]
        print(f"è¿‡æ»¤åæ•°æ®é›†æ ·æœ¬æ•°ï¼š{len(self.raw_dataset_samples)}")

        # æ„å»ºé¢„å¤„ç†â†’åŸå§‹åºåˆ—æ˜ å°„
        protein_proc2raw = {}
        ligand_proc2raw = {}

        for raw_p in dataset["Target"]:
            proc_p = self.preprocess_protein(raw_p)
            if proc_p not in protein_proc2raw:
                protein_proc2raw[proc_p] = raw_p

        for raw_l in dataset["Drug"]:
            proc_l = self.preprocess_ligand(raw_l)
            if proc_l not in ligand_proc2raw:
                ligand_proc2raw[proc_l] = raw_l

        # æå–å”¯ä¸€åºåˆ—
        unique_proteins = list(protein_proc2raw.keys())[:max_proteins]
        unique_ligands = list(ligand_proc2raw.keys())[:max_ligands]
        print(f"æœ‰æ•ˆæ ·æœ¬ï¼šè›‹ç™½{len(unique_proteins)}æ¡ï¼ˆé™åˆ¶{max_proteins}ï¼‰ï¼Œå°åˆ†å­{len(unique_ligands)}æ¡ï¼ˆé™åˆ¶{max_ligands}ï¼‰")

        # æ‰¹é‡ç¼–ç è›‹ç™½
        batch_size = 32
        protein_embs = []
        for i in tqdm(range(0, len(unique_proteins), batch_size), desc="ç¼–ç protein"):
            batch_seqs = unique_proteins[i:i + batch_size]
            batch_embs = self.encode_protein_batch(batch_seqs)
            protein_embs.append(batch_embs)
        protein_embs = np.concatenate(protein_embs, axis=0)

        # æ‰¹é‡ç¼–ç å°åˆ†å­
        ligand_embs = []
        for i in tqdm(range(0, len(unique_ligands), batch_size), desc="ç¼–ç ligand"):
            batch_smiles = unique_ligands[i:i + batch_size]
            batch_embs = self.encode_ligand_batch(batch_smiles)
            ligand_embs.append(batch_embs)
        ligand_embs = np.concatenate(ligand_embs, axis=0)

        # æ„å»ºIDæ˜ å°„
        self.protein_id2seq = {
            i: {
                "processed": seq,
                "raw": protein_proc2raw.get(seq, seq)
            } for i, seq in enumerate(unique_proteins)
        }
        self.ligand_id2smiles = {
            i: {
                "processed": smi,
                "raw": ligand_proc2raw.get(smi, smi)
            } for i, smi in enumerate(unique_ligands)
        }

        # æ„å»ºFAISSç´¢å¼•
        self.protein_index = faiss.IndexFlatIP(256)
        self.protein_index.add(protein_embs)
        print(f"protein FAISSç´¢å¼•æ„å»ºå®Œæˆï¼š{len(unique_proteins)}ä¸ªæ ·æœ¬ï¼Œç»´åº¦256")

        self.ligand_index = faiss.IndexFlatIP(256)
        self.ligand_index.add(ligand_embs)
        print(f"ligand FAISSç´¢å¼•æ„å»ºå®Œæˆï¼š{len(unique_ligands)}ä¸ªæ ·æœ¬ï¼Œç»´åº¦256")

        # æ„å»ºäº²å’ŒåŠ›æ•°æ®åº“
        self.affinity_db = {}
        raw_affinity_db = {}

        for sample in tqdm(dataset, desc="æ„å»ºåŸå§‹äº²å’ŒåŠ›æ•°æ®åº“"):
            raw_p = sample["Target"].upper()
            raw_l = sample["Drug"].replace(' ', '').lower()
            y_val = sample["Y"]
            raw_affinity_db[(raw_p, raw_l)] = y_val

        # å­˜å‚¨å¤šæ ¼å¼ç»„åˆ
        for (raw_p, raw_l), y_val in raw_affinity_db.items():
            proc_p = self.preprocess_protein(raw_p)
            proc_l = self.preprocess_ligand(raw_l)
            self.affinity_db[(raw_p, raw_l)] = y_val
            self.affinity_db[(proc_p, proc_l)] = y_val
            self.affinity_db[(raw_p, proc_l)] = y_val
            self.affinity_db[(proc_p, raw_l)] = y_val

        # è°ƒè¯•ä¿¡æ¯
        print("\n=== äº²å’ŒåŠ›æ•°æ®åº“è°ƒè¯•ä¿¡æ¯ ===")
        print(f"äº²å’ŒåŠ›æ•°æ®åº“æ€»é”®æ•°ï¼š{len(self.affinity_db)}")
        db_keys = list(self.affinity_db.keys())[:5]
        print(f"æ•°æ®åº“å‰5ä¸ªé”®ç¤ºä¾‹ï¼š{db_keys}")

    def _get_affinity_with_fallback(self, protein_seq, ligand_smiles):
        """
        æœ€ç»ˆä¿®å¤ç‰ˆäº²å’ŒåŠ›æŸ¥è¯¢ï¼š
        1. ç²¾ç¡®åŒ¹é…
        2. è›‹ç™½åŒ¹é…+å°åˆ†å­æ¨¡ç³ŠåŒ¹é…ï¼ˆå–æœ€å¤§äº²å’ŒåŠ›ï¼‰
        3. è›‹ç™½å‰ç¼€åŒ¹é…ï¼ˆå–æœ€å¤§äº²å’ŒåŠ›ï¼‰
        """
        # å½’ä¸€åŒ–æŸ¥è¯¢åºåˆ—
        p_norm = protein_seq.upper()
        l_norm = ligand_smiles.replace(' ', '').lower()
        proc_p = self.preprocess_protein(p_norm)
        proc_l = self.preprocess_ligand(l_norm)

        # 1. ç²¾ç¡®åŒ¹é…
        affinity = self.affinity_db.get((p_norm, l_norm),
                    self.affinity_db.get((p_norm, proc_l),
                    self.affinity_db.get((proc_p, l_norm),
                    self.affinity_db.get((proc_p, proc_l), -1))))

        # 2. è›‹ç™½ç²¾ç¡®åŒ¹é… + å°åˆ†å­ä»»æ„åŒ¹é…ï¼ˆå–æœ€å¤§äº²å’ŒåŠ›ï¼‰
        if affinity == -1:
            protein_matches = []
            for (db_p, db_l), y_val in self.affinity_db.items():
                if db_p == p_norm or db_p == proc_p:
                    protein_matches.append(y_val)

            if protein_matches:
                affinity = max(protein_matches)

        # 3. è›‹ç™½å‰ç¼€åŒ¹é…ï¼ˆå‰50å­—ç¬¦ï¼‰+ å–æœ€å¤§äº²å’ŒåŠ›
        if affinity == -1:
            prefix_matches = []
            for (db_p, db_l), y_val in self.affinity_db.items():
                if db_p[:50] == p_norm[:50] or db_p[:50] == proc_p[:50]:
                    prefix_matches.append(y_val)

            if prefix_matches:
                affinity = max(prefix_matches)

        # 4. æœ€ç»ˆå…œåº•
        return affinity if affinity != -1 else 0.0

    def retrieve_ligands(self, protein_seq, top_k=10):
        """æ£€ç´¢ç»™å®šè›‹ç™½çš„é«˜äº²å’ŒåŠ›å°åˆ†å­"""
        # ç¼–ç æŸ¥è¯¢è›‹ç™½
        query_emb = self.encode_protein_batch([protein_seq])[0].reshape(1, -1)

        # FAISSæ£€ç´¢
        distances, indices = self.ligand_index.search(query_emb, top_k)

        # å½’ä¸€åŒ–ç›¸ä¼¼åº¦åˆ°0~1
        max_sim = np.max(distances[0]) if len(distances[0]) > 0 else 1.0
        min_sim = np.min(distances[0]) if len(distances[0]) > 0 else 0.0
        norm_distances = (distances[0] - min_sim) / (max_sim - min_sim + 1e-8)

        # è§£æç»“æœ
        results = []
        for i, idx in enumerate(indices[0]):
            if 0 <= idx < len(self.ligand_id2smiles):
                ligand_info = self.ligand_id2smiles[idx]
                raw_l = ligand_info["raw"]
                # ä½¿ç”¨ä¿®å¤åçš„äº²å’ŒåŠ›æŸ¥è¯¢å‡½æ•°
                affinity = self._get_affinity_with_fallback(protein_seq, raw_l)

                results.append({
                    "smiles": raw_l,
                    "smiles_processed": ligand_info["processed"],
                    "similarity": norm_distances[i],
                    "affinity": affinity
                })

        return results

    def retrieve_proteins(self, ligand_smiles, top_k=10):
        """æ£€ç´¢ç»™å®šå°åˆ†å­çš„é«˜äº²å’ŒåŠ›è›‹ç™½"""
        # ç¼–ç æŸ¥è¯¢å°åˆ†å­
        query_emb = self.encode_ligand_batch([ligand_smiles])[0].reshape(1, -1)

        # FAISSæ£€ç´¢
        distances, indices = self.protein_index.search(query_emb, top_k)

        # å½’ä¸€åŒ–ç›¸ä¼¼åº¦åˆ°0~1
        max_sim = np.max(distances[0]) if len(distances[0]) > 0 else 1.0
        min_sim = np.min(distances[0]) if len(distances[0]) > 0 else 0.0
        norm_distances = (distances[0] - min_sim) / (max_sim - min_sim + 1e-8)

        # è§£æç»“æœ
        results = []
        for i, idx in enumerate(indices[0]):
            if 0 <= idx < len(self.protein_id2seq):
                protein_info = self.protein_id2seq[idx]
                raw_p = protein_info["raw"]
                # ä½¿ç”¨ä¿®å¤åçš„äº²å’ŒåŠ›æŸ¥è¯¢å‡½æ•°
                affinity = self._get_affinity_with_fallback(raw_p, ligand_smiles)

                results.append({
                    "protein_seq": raw_p,
                    "protein_processed": protein_info["processed"],
                    "similarity": norm_distances[i],
                    "affinity": affinity
                })

        return results

# ==================== ä¸»æµ‹è¯•ç¨‹åºï¼ˆæœ€ç»ˆç‰ˆï¼‰ ====================
if __name__ == "__main__":
    # 1. é…ç½®å‚æ•°
    CHECKPOINT_PATH = "C:/czx/Project/Grade0/recommender_system_project/protein-ligand-recommender/model/checkpoints/clip_tower_best-v9.ckpt"
    CHECKPOINT_PATH = "../model/checkpoints/clip_tower_best-v9.ckpt"
    DEVICE = "cuda:0"
    TEMPERATURE_SCALE = 0.5

    # 2. åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = ProteinLigandRetriever(
        checkpoint_path=CHECKPOINT_PATH,
        device=DEVICE,
        temperature_scale=TEMPERATURE_SCALE
    )

    # 3. åŠ è½½æ•°æ®é›†å¹¶æ„å»ºç´¢å¼•
    try:
        from datasets import load_dataset
        ds = load_dataset("BALM/BALM-benchmark", "BindingDB_filtered")
        retriever.build_indexes_from_dataset(
            ds,
            max_proteins=2000,
            max_ligands=8000
        )
    except Exception as e:
        print(f"åŠ è½½æ•°æ®é›†å¤±è´¥ï¼š{e}")
        exit(1)

    # 4. é€‰æ‹©å¹¶éªŒè¯æµ‹è¯•æ ·æœ¬
    print("\n=== ä»æ•°æ®é›†é€‰æ‹©å¹¶éªŒè¯æµ‹è¯•æ ·æœ¬ ===")
    test_protein = ""
    test_smiles = ""
    target_protein = ""
    target_smiles = ""
    real_affinity = 0.0

    if len(retriever.raw_dataset_samples) > 0:
        # é€‰æ‹©ç¬¬ä¸€ä¸ªæ ·æœ¬
        real_sample = retriever.raw_dataset_samples[0]
        test_protein = real_sample["Target"]
        test_smiles = real_sample["Drug"]
        target_protein = test_protein
        target_smiles = test_smiles

        print(f"ğŸ“Œ æµ‹è¯•è›‹ç™½ï¼ˆå‰60å­—ç¬¦ï¼‰ï¼š{test_protein[:60]}...")
        print(f"ğŸ“Œ æµ‹è¯•SMILESï¼š{test_smiles}")

        # éªŒè¯äº²å’ŒåŠ›åŒ¹é…
        print("\n=== éªŒè¯äº²å’ŒåŠ›åŒ¹é… ===")
        test_p_norm = test_protein.upper()
        test_l_norm = test_smiles.replace(' ', '').lower()

        # 1. ç²¾ç¡®åŒ¹é…
        exact_affinity = retriever.affinity_db.get((test_p_norm, test_l_norm), -1)
        if exact_affinity != -1:
            real_affinity = exact_affinity
            print(f"âœ… ç²¾ç¡®åŒ¹é…æˆåŠŸï¼äº²å’ŒåŠ›å€¼ï¼š{real_affinity:.2f}")
        else:
            # 2. è›‹ç™½åŒ¹é…å–æœ€å¤§äº²å’ŒåŠ›
            protein_matches = []
            for (db_p, db_l), y_val in retriever.affinity_db.items():
                if db_p == test_p_norm or db_p[:50] == test_p_norm[:50]:
                    protein_matches.append(y_val)

            if protein_matches:
                real_affinity = max(protein_matches)
                print(f"âš ï¸  ç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå–è›‹ç™½åŒ¹é…çš„æœ€å¤§äº²å’ŒåŠ›ï¼š{real_affinity:.2f}")
            else:
                real_affinity = 0.0
                print(f"âŒ æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„äº²å’ŒåŠ›å€¼")

        print(f"ğŸ“Œ æœ€ç»ˆä½¿ç”¨çš„äº²å’ŒåŠ›å€¼ï¼š{real_affinity:.2f}")
    else:
        # å…œåº•ç”¨ä¾‹
        test_protein = "MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKPLSVSYDQATSLRIL"
        test_smiles = "Cc1ccc(CNS(=O)(=O)c2ccc(S(N)(=O)=O)s2)cc1"
        target_protein = test_protein
        target_smiles = test_smiles
        print("âš ï¸  æ•°æ®é›†ä¸ºç©ºï¼Œä½¿ç”¨å…œåº•æµ‹è¯•ç”¨ä¾‹")

    # 5. æµ‹è¯•1ï¼šè›‹ç™½â†’å°åˆ†å­æ¨è
    print("\n=== æµ‹è¯•1ï¼šè›‹ç™½â†’å°åˆ†å­æ¨è ===")
    print(f"æŸ¥è¯¢è›‹ç™½ï¼š{test_protein[:60]}...")
    ligand_results = retriever.retrieve_ligands(test_protein, top_k=10)
    for i, res in enumerate(ligand_results):
        smiles_display = res['smiles'][:50] + "..." if len(res['smiles']) > 50 else res['smiles']
        print(f"Top{i+1}ï¼šSMILES={smiles_display} | ç›¸ä¼¼åº¦={res['similarity']:.4f} | äº²å’ŒåŠ›={res['affinity']:.2f}")

    # 6. æµ‹è¯•2ï¼šå°åˆ†å­â†’è›‹ç™½æ¨è
    print("\n=== æµ‹è¯•2ï¼šå°åˆ†å­â†’è›‹ç™½æ¨è ===")
    print(f"æŸ¥è¯¢SMILESï¼š{test_smiles}")
    protein_results = retriever.retrieve_proteins(test_smiles, top_k=10)
    for i, res in enumerate(protein_results):
        seq_display = res['protein_seq'][:60] + "..." if len(res['protein_seq']) > 60 else res['protein_seq']
        print(f"Top{i+1}ï¼šè›‹ç™½åºåˆ—={seq_display} | ç›¸ä¼¼åº¦={res['similarity']:.4f} | äº²å’ŒåŠ›={res['affinity']:.2f}")

    # 7. æµ‹è¯•3ï¼šæ•°æ®é›†å¤–è›‹ç™½ï¼ˆèƒ°å²›ç´ ï¼‰
    insulin_protein = "MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGERGFFYTPKTRREAEDLQVGQVELGGGPGAGSLQPLALEGSLQKRGIVEQCCTSICSLYQLENYCN"
    print("\n=== æµ‹è¯•4ï¼šæ•°æ®é›†å¤–æ¨èï¼ˆèƒ°å²›ç´ ï¼‰ ===")
    print(f"æŸ¥è¯¢èƒ°å²›ç´ è›‹ç™½ï¼š{insulin_protein[:60]}...")
    insulin_results = retriever.retrieve_ligands(insulin_protein, top_k=3)
    max_sim = max([r['similarity'] for r in insulin_results] + [1e-8])
    for i, res in enumerate(insulin_results):
        smiles_display = res['smiles'][:50] + "..." if len(res['smiles']) > 50 else res['smiles']
        norm_sim = res['similarity'] / max_sim if max_sim > 1e-8 else 0.0
        print(f"Top{i+1}ï¼šSMILES={smiles_display} | ç›¸ä¼¼åº¦={res['similarity']:.4f} | å½’ä¸€åŒ–ç›¸ä¼¼åº¦={norm_sim:.4f} | äº²å’ŒåŠ›={res['affinity']:.2f}")

    # 8. æµ‹è¯•6ï¼šéªŒè¯é«˜äº²å’ŒåŠ›ç»“åˆå¯¹
    print("\n=== æµ‹è¯•6ï¼šéªŒè¯ç›®æ ‡ç»“åˆå¯¹æ£€ç´¢ ===")
    target_smiles_norm = target_smiles.replace(' ', '').lower()
    retrieval_results = retriever.retrieve_ligands(target_protein, top_k=10)

    found = False
    for i, res in enumerate(retrieval_results):
        res_smiles_norm = res['smiles'].replace(' ', '').lower()
        if res_smiles_norm == target_smiles_norm or res_smiles_norm[:50] == target_smiles_norm[:50]:
            found = True
            print(f"âœ… åœ¨Top{i+1}æ‰¾åˆ°ç›®æ ‡å°åˆ†å­ï¼")
            print(f"   SMILESï¼š{res['smiles'][:80]}...")
            print(f"   ç›¸ä¼¼åº¦ï¼š{res['similarity']:.4f} | äº²å’ŒåŠ›ï¼š{res['affinity']:.2f}")
            break

    if not found:
        print(f"âŒ æœªåœ¨Top10æ‰¾åˆ°ç›®æ ‡å°åˆ†å­ï¼ŒTop10ç»“æœï¼š")
        for i, res in enumerate(retrieval_results):
            smiles_display = res['smiles'][:50] + "..." if len(res['smiles']) > 50 else res['smiles']
            print(f"Top{i+1}ï¼šSMILES={smiles_display} | ç›¸ä¼¼åº¦={res['similarity']:.4f} | äº²å’ŒåŠ›={res['affinity']:.2f}")

    print("\n=== æ‰€æœ‰æµ‹è¯•å®Œæˆ ===")